{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq with attention(fra)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWK7ehZEPJ5T",
        "outputId": "5739d1bb-fd75-4ef7-936c-5cdde28c912e"
      },
      "source": [
        "# ================================================================================ #\n",
        "# =========================== Goolge Colab File Upload =========================== #\n",
        "# ================================================================================ #\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import output\n",
        "# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/DIYA time series/AttentionLayerExample/Dataset/fra.txt\" \"fra.txt\"\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "drive  fra.txt\tkor.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "mEb21u7uP2C4",
        "outputId": "94a19dfd-3540-4da9-c3d9-65e4ec11879c"
      },
      "source": [
        "import pandas as pd\n",
        "import re \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "path = \"./fra.txt\"\n",
        "df_fra = pd.read_csv(path, names = [\"src\", \"tar\", \"lic\"], sep = \"\\t\")\n",
        "\n",
        "del df_fra[\"lic\"]\n",
        "display(df_fra)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189109</th>\n",
              "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
              "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189110</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189111</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189112</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189113</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>189114 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      src                                                tar\n",
              "0                                                     Go.                                               Va !\n",
              "1                                                     Go.                                            Marche.\n",
              "2                                                     Go.                                            Bouge !\n",
              "3                                                     Hi.                                            Salut !\n",
              "4                                                     Hi.                                             Salut.\n",
              "...                                                   ...                                                ...\n",
              "189109  Top-down economics never works, said Obama. \"T...  « L'économie en partant du haut vers le bas, ç...\n",
              "189110  A carbon footprint is the amount of carbon dio...  Une empreinte carbone est la somme de pollutio...\n",
              "189111  Death is something that we're often discourage...  La mort est une chose qu'on nous décourage sou...\n",
              "189112  Since there are usually multiple websites on a...  Puisqu'il y a de multiples sites web sur chaqu...\n",
              "189113  If someone who doesn't know your background sa...  Si quelqu'un qui ne connaît pas vos antécédent...\n",
              "\n",
              "[189114 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSSraJoYQFti",
        "outputId": "96c05347-9b74-4c1b-8723-2bb4a6846e9b"
      },
      "source": [
        "# library\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "dataset = df_fra[[\"src\", \"tar\"]].iloc[:,:]\n",
        "\n",
        "# preprocessing function\n",
        "\n",
        "def preprocess_eng(sent):\n",
        "    \n",
        "    # 단어 - 구두점 사이의 공간 1 생성\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "    \n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고 전부 공백 전환\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "    \n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    \n",
        "    return sent\n",
        "\n",
        "def preprocess_fra(sent):\n",
        "\n",
        "    # 단어 - 구두점 사이의 공간 1 생성\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "    \n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고 전부 공백 전환\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "    \n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)    \n",
        "\n",
        "    \n",
        "    return sent"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 266kB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 40.3MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rWtofC_Q4Sm",
        "outputId": "0cea41bd-c6e2-47c6-9271-a3a9f8c97514"
      },
      "source": [
        "test_sent_kor_pre.append(\"<sos>\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "['너는', '뉴욕에', '가본', '적', '있니', '?', '<sos>', '<sos>', '<sos>', '<sos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYyvo_YEQgSu",
        "outputId": "61b5a220-bc4a-4db3-97bd-5592652d24e9"
      },
      "source": [
        "def load_data(df = dataset, data_size = None):\n",
        "    df_src = df[\"src\"]\n",
        "    df_tar = df[\"tar\"]\n",
        "    \n",
        "    if data_size is None:\n",
        "        data_size = len(df)\n",
        "        \n",
        "    encoder_input, decoder_input, decoder_output = [], [], []\n",
        "    \n",
        "    for i in range(1,data_size):\n",
        "        src_line, tar_line = df_src.iloc[i], df_tar.iloc[i]\n",
        "        \n",
        "        # source data preprocessing -> word level separation\n",
        "        src_line_input = [w for w in preprocess_eng(src_line).split()]\n",
        "        \n",
        "        # target data preprocessing -> word level separation\n",
        "        tar_line = preprocess_fra(tar_line)\n",
        "        tar_line_input = tar_line\n",
        "        tar_line_output = tar_line\n",
        "\n",
        "        #tar_line_input.insert(0, \"<sos>\")\n",
        "        #tar_line_output.append(\"<eos>\")\n",
        "\n",
        "        tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "        tar_line_output = [w for w in (tar_line + \" <eos>\").split()]\n",
        "        \n",
        "        encoder_input.append(src_line_input)\n",
        "        decoder_input.append(tar_line_input)\n",
        "        decoder_output.append(tar_line_output)\n",
        "        \n",
        "        del src_line, tar_line, tar_line_input, tar_line_output, src_line_input\n",
        "    \n",
        "    return encoder_input, decoder_input, decoder_output\n",
        "\n",
        "\n",
        "sent_eng_in, sent_fra_in, sent_fra_out = load_data(dataset, 100000)\n",
        "\n",
        "# word set \n",
        "\n",
        "tokenizer_eng = Tokenizer(filters = \"\", lower = False)\n",
        "tokenizer_fra = Tokenizer(filters = \"\", lower = False)\n",
        "\n",
        "tokenizer_eng.fit_on_texts(sent_eng_in)\n",
        "encoder_input = tokenizer_eng.texts_to_sequences(sent_eng_in)\n",
        "\n",
        "tokenizer_fra.fit_on_texts(sent_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sent_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sent_fra_in)\n",
        "decoder_output = tokenizer_fra.texts_to_sequences(sent_fra_out)\n",
        "\n",
        "encoder_input = pad_sequences(encoder_input, padding = \"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding = \"post\")\n",
        "decoder_output = pad_sequences(decoder_output, padding = \"post\")\n",
        "\n",
        "print(\"encoder_input: \",encoder_input.shape)\n",
        "print(\"decoder_input: \",decoder_input.shape)\n",
        "print(\"decoder_output: \", decoder_output.shape)\n",
        "\n",
        "# define word set for src, tar data\n",
        "\n",
        "src_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))\n",
        "\n",
        "src_to_index = tokenizer_eng.word_index\n",
        "index_to_src = tokenizer_eng.index_word # 훈련 후 결과 비교할 때 사용\n",
        "\n",
        "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
        "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용\n",
        "\n",
        "# train test split\n",
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "n_of_val = int(len(indices) * 0.1)\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_output_train = decoder_output[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_output_test = decoder_output[-n_of_val:]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_input:  (99999, 10)\n",
            "decoder_input:  (99999, 19)\n",
            "decoder_output:  (99999, 19)\n",
            "영어 단어 집합의 크기 : 9660, 프랑스어 단어 집합의 크기 : 14420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj3f8xn_Ql0_"
      },
      "source": [
        "# model architecture\n",
        "import tensorflow as tf\n",
        "\n",
        "# seq2seq model(train)\n",
        "def seq2seq_model(\n",
        "    encoder_input_shapes = encoder_input_train.shape[1:],\n",
        "    decoder_input_shapes = decoder_input_train.shape[1:],\n",
        "    embed_dim = 64):\n",
        "\n",
        "    # for test model: translation 과정에서 재호출할 필요가 있는 레이어 집합\n",
        "    layers_test = []\n",
        "\n",
        "    # encoder\n",
        "    encoder_inputs = tf.keras.layers.Input(shape = encoder_input_shapes, name = \"encoder_input\")\n",
        "    x_enc = tf.keras.layers.Embedding(src_vocab_size, embed_dim, name = \"encoder_embed\")(encoder_inputs)\n",
        "    x_enc = tf.keras.layers.Masking(mask_value = 0.0)(x_enc)\n",
        "    x_enc, h, c = tf.keras.layers.LSTM(256, return_sequences = True, return_state = True, name = \"encoder_lstm\")(x_enc)\n",
        "    enc_states = [h,c]\n",
        "\n",
        "    layers_test.append(encoder_inputs)\n",
        "    layers_test.append(enc_states)\n",
        "    \n",
        "    # decoder\n",
        "    decoder_inputs = tf.keras.layers.Input(shape = decoder_input_shapes, name = \"decoder_input\")\n",
        "    decoder_embed = tf.keras.layers.Embedding(tar_vocab_size, embed_dim, name = \"decoder_embed\")\n",
        "    x_dec = decoder_embed(decoder_inputs)\n",
        "    x_dec = tf.keras.layers.Masking(mask_value = 0.0)(x_dec)\n",
        "    \n",
        "    decoder_lstm = tf.keras.layers.LSTM(256, return_sequences = True, return_state = True, name = \"decoder_lstm\")\n",
        "    dec_outputs, _, _ = decoder_lstm(x_dec, initial_state = enc_states)\n",
        "\n",
        "    decoder_softmax = tf.keras.layers.Dense(tar_vocab_size, activation = \"softmax\")\n",
        "    decoder_outputs = decoder_softmax(dec_outputs)\n",
        "    \n",
        "    model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs, name = \"seq2seq\")\n",
        "    model.summary()\n",
        "\n",
        "    layers_test.append(decoder_inputs)\n",
        "    layers_test.append(decoder_embed)\n",
        "    layers_test.append(decoder_lstm)\n",
        "    layers_test.append(decoder_softmax)\n",
        "    \n",
        "    # compile model\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
        "    loss = 'sparse_categorical_crossentropy'\n",
        "    metrics = [\"acc\"]\n",
        "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "\n",
        "    return model, layers_test\n",
        "\n",
        "# seq2seq model(test)\n",
        "def test_seq2seq_model(train_model, layers_test, hidden_dims = 256):\n",
        "\n",
        "    # reload the trained layer\n",
        "    encoder_inputs = layers_test[0]\n",
        "    encoder_states = layers_test[1]\n",
        "    decoder_inputs = layers_test[2]\n",
        "    decoder_embed = layers_test[3]\n",
        "    decoder_lstm = layers_test[4]\n",
        "    decoder_softmax = layers_test[5]\n",
        "\n",
        "    # encoder model\n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states, name = \"encoder\")\n",
        "\n",
        "    # decoder model\n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape = (hidden_dims,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape = (hidden_dims,))\n",
        "    decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    dec_embed2 = decoder_embed(decoder_inputs)\n",
        "\n",
        "    decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(dec_embed2, initial_state = decoder_state_inputs)\n",
        "\n",
        "    decoder_states = [decoder_state_h, decoder_state_c]\n",
        "\n",
        "    decoder_outputs = decoder_softmax(decoder_outputs)\n",
        "\n",
        "    decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states, name = \"decoder\")\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "\n",
        "# prediction(translate)\n",
        "\n",
        "def decode_sequence(input_seq, encoder_model, decoder_model):\n",
        "    state_h = encoder_model.predict(input_seq)\n",
        "\n",
        "    #<sos> 에 대응되는 정수 인덱스 부여\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0,0] = tar_to_index['<sos>']\n",
        "    \n",
        "    stop_cond = False\n",
        "    decode_sentence = ''\n",
        "\n",
        "    while not stop_cond:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + state_h)\n",
        "\n",
        "        # 예측 결과를 단어로 변환\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        if sampled_token_index ==0:\n",
        "            break\n",
        "        else:\n",
        "            sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        # 결과를 문장에 추가\n",
        "        decode_sentence += \" \" + sampled_char \n",
        "\n",
        "        # stop condition\n",
        "        if (sampled_char == '<eos>' or len(decode_sentence) >= 50):\n",
        "            stop_cond = True\n",
        "\n",
        "        # 예측된 결과를 다음 hidden_state로 반영\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0,0] = sampled_token_index\n",
        "\n",
        "        state_h = [h,c]\n",
        "    \n",
        "    return decode_sentence"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1YLew3nd7js",
        "outputId": "3952004e-0109-4479-a108-08e4c8f20c3c"
      },
      "source": [
        "train_model, layers_test = seq2seq_model(embed_dim = 128)\n",
        "\n",
        "# learning parameter\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 8, verbose = 0, mode = \"min\")\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(\"seq2seq_model.h5\", monitor = \"val_loss\", verbose = 0, save_best_only = True, mode = \"min\")\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor = np.sqrt(0.1), patience = 8, verbose = 0, mode = \"min\")\n",
        "\n",
        "call_params = [es, mc, lr]\n",
        "\n",
        "# train model\n",
        "train_model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, \n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), epochs = 64,\n",
        "         batch_size = 128, verbose = 1, callbacks = call_params)\n",
        "\n",
        "enc, dec = test_seq2seq_model(train_model, layers_test, hidden_dims = 256)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"seq2seq\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      [(None, 19)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_embed (Embedding)       (None, 10, 128)      1236480     encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_embed (Embedding)       (None, 19, 128)      1845760     decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "masking_8 (Masking)             (None, 10, 128)      0           encoder_embed[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "masking_9 (Masking)             (None, 19, 128)      0           decoder_embed[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 10, 256), (N 394240      masking_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, 19, 256), (N 394240      masking_9[0][0]                  \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 19, 14420)    3705940     decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,576,660\n",
            "Trainable params: 7,576,660\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/64\n",
            "704/704 [==============================] - 62s 76ms/step - loss: 1.4614 - acc: 0.7691 - val_loss: 1.4562 - val_acc: 0.7450\n",
            "Epoch 2/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.8951 - acc: 0.8279 - val_loss: 1.2857 - val_acc: 0.7699\n",
            "Epoch 3/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.7222 - acc: 0.8476 - val_loss: 1.2381 - val_acc: 0.7793\n",
            "Epoch 4/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.6213 - acc: 0.8600 - val_loss: 1.2274 - val_acc: 0.7831\n",
            "Epoch 5/64\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.5527 - acc: 0.8695 - val_loss: 1.2353 - val_acc: 0.7871\n",
            "Epoch 6/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.5005 - acc: 0.8777 - val_loss: 1.2525 - val_acc: 0.7884\n",
            "Epoch 7/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.4619 - acc: 0.8841 - val_loss: 1.2746 - val_acc: 0.7906\n",
            "Epoch 8/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.4325 - acc: 0.8892 - val_loss: 1.2900 - val_acc: 0.7911\n",
            "Epoch 9/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.4095 - acc: 0.8934 - val_loss: 1.3141 - val_acc: 0.7927\n",
            "Epoch 10/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.3918 - acc: 0.8964 - val_loss: 1.3423 - val_acc: 0.7910\n",
            "Epoch 11/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.3778 - acc: 0.8991 - val_loss: 1.3665 - val_acc: 0.7926\n",
            "Epoch 12/64\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.3668 - acc: 0.9012 - val_loss: 1.3875 - val_acc: 0.7928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q_n4N39RiOy"
      },
      "source": [
        "# test\n",
        "input_sentence = \"I love chicken very much~!\"\n",
        "decode_sentence(input_seq, enc, dec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JALfGvjsfUu2",
        "outputId": "6f80eca7-6745-451e-a707-98d8a01f690a"
      },
      "source": [
        "def seq2src(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            temp = temp + index_to_src[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2tar(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if((i!= 0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
        "            temp = temp + index_to_tar[i] + ' '\n",
        "    return temp\n",
        "\n",
        "for seq_index in [3,10,25,50,100,150,300,500,750,1000,1500, 1750, 2000, 2500]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq, enc, dec)\n",
        "\n",
        "  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
        "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
        "  print(\"예측문 :\",decoded_sentence)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 19) for input KerasTensor(type_spec=TensorSpec(shape=(None, 19), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "원문 :  Hi . \n",
            "번역문 : Salut . \n",
            "예측문 :  Salut ! <eos>\n",
            "\n",
            "\n",
            "원문 :  Run ! \n",
            "번역문 : Fuyez ! \n",
            "예측문 :  Cours ! <eos>\n",
            "\n",
            "\n",
            "원문 :  Hide . \n",
            "번역문 : Cachez vous . \n",
            "예측문 :  Cache toi . <eos>\n",
            "\n",
            "\n",
            "원문 :  I won . \n",
            "번역문 : J ai gagn . \n",
            "예측문 :  Je l ai emport ! <eos>\n",
            "\n",
            "\n",
            "원문 :  I knit . \n",
            "번역문 : Je tricote . \n",
            "예측문 :  Je tricote . <eos>\n",
            "\n",
            "\n",
            "원문 :  Be fair . \n",
            "번역문 : Soyez justes ! \n",
            "예측문 :  Soyez quitable ! <eos>\n",
            "\n",
            "\n",
            "원문 :  I agree . \n",
            "번역문 : Je suis du m me avis . \n",
            "예측문 :  Je suis d accord . <eos>\n",
            "\n",
            "\n",
            "원문 :  Get lost ! \n",
            "번역문 : D gage ! \n",
            "예측문 :  Soyez ponctuels ! <eos>\n",
            "\n",
            "\n",
            "원문 :  Terrific ! \n",
            "번역문 : Nickel chrome ! \n",
            "예측문 :  C est minable . <eos>\n",
            "\n",
            "\n",
            "원문 :  I give in . \n",
            "번역문 : Je donne ma langue au chat . \n",
            "예측문 :  J ai oubli . <eos>\n",
            "\n",
            "\n",
            "원문 :  Try again . \n",
            "번역문 : Essayez de nouveau . \n",
            "예측문 :  Essaie de nouveau . <eos>\n",
            "\n",
            "\n",
            "원문 :  Follow Tom . \n",
            "번역문 : Suis Tom . \n",
            "예측문 :  Suivez Tom . <eos>\n",
            "\n",
            "\n",
            "원문 :  I was lost . \n",
            "번역문 : J tais perdu . \n",
            "예측문 :  J ai t chanceux . <eos>\n",
            "\n",
            "\n",
            "원문 :  We saw you . \n",
            "번역문 : Nous vous avons vus . \n",
            "예측문 :  Nous vous avons vus . <eos>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSmAvOHbBvIz"
      },
      "source": [
        "# attention layer\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # values: hidden states from encoder\n",
        "        # query: hiden states from decoder, (batch_size, hidden_size)\n",
        "\n",
        "        ht = tf.expand_dims(query, 1) # (batch_size, 1, hidden_size)\n",
        "        score = self.V(tf.nn.tanh(self.W1(ht) + self.W2(values)))\n",
        "        alpha_t = tf.nn.softmax(score, axis = 1) #(batch_size, max_length, 1), attention_weights\n",
        "        context_vector = alpha_t * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "\n",
        "        return context_vector, alpha_t\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.models.Model):\n",
        "    def __init__(self, embed_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(src_vocab_size, embed_dims)\n",
        "        self.lstm = tf.keras.layers.LSTM(256, return_sequences = True, return_state = True)\n",
        "        self.masking = tf.keras.layers.Masking(mask_value = 0.0)\n",
        "\n",
        "    def call(self, inputs, h_init = None, c_init = None):\n",
        "        x = self.embed(inputs)\n",
        "        x = self.masking(x)\n",
        "        x, h, c = self.lstm(x, initial_state = [h_init, c_init])\n",
        "        return x, h, c\n",
        "\n",
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, embed_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(tar_vocab_size, embed_dims)\n",
        "        self.lstm = tf.keras.layers.LSTM(256, return_state = True, return_sequences=True)\n",
        "        self.masking = tf.keras.layers.Masking(mask_value = 0.0)\n",
        "        self.attention = BahdanauAttention(embed_dims)\n",
        "        self.softmax = tf.keras.layers.Dense(tar_vocab_size, activation = \"softmax\")\n",
        "\n",
        "    def call(self, x, h, c, enc_output):\n",
        "        \n",
        "        # 최초에는 t-1번째 hidden_state(decoder) = enc_output\n",
        "        # x: decoder input\n",
        "        # h: encoder hidden state(last)\n",
        "        # c: encoder cell state(last)\n",
        "\n",
        "        # attention units: embed_dims\n",
        "        # context_vector: (batch_size, embed_dims)\n",
        "        # alpha_t : (batch_size, max_len)\n",
        "        context_vector, alpha_t = self.attention(h, enc_output)\n",
        "\n",
        "        # embedding: (batch_size, target_max_len, embed_dims)\n",
        "        x = self.embed(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "\n",
        "        x, dec_h, dec_c = self.lstm(x,initial_state = [h,c])\n",
        "        outputs = self.softmax(x)\n",
        "\n",
        "        return outputs, dec_h, dec_c\n",
        "\n",
        "\n",
        "# dataloader with batch size\n",
        "\n",
        "def data_batch(train_x_enc, train_x_dec, train_y_dec, batch_size = 32):\n",
        "\n",
        "    # shuffle data\n",
        "    index = np.arange(0, train_x_enc.shape[0])\n",
        "    np.random.shuffle(index)\n",
        "\n",
        "    # batch\n",
        "    epochs = int(train_x_enc.shape[0] / batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        batch_x_enc = train_x_enc[batch_size * epoch : batch_size * (epoch + 1),:]\n",
        "        batch_x_dec = train_x_dec[batch_size * epoch : batch_size * (epoch + 1),:]\n",
        "\n",
        "        batch_y_dec = train_y_dec[batch_size * epoch : batch_size * (epoch + 1),:]\n",
        "\n",
        "        yield batch_x_enc, batch_x_dec, batch_y_dec\n",
        "\n",
        "\n",
        "# model train\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
        "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = \"none\")\n",
        "\n",
        "def loss_func(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_obj(real, pred)\n",
        "    mask = tf.cast(mask, dtype = loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# model build\n",
        "embed_dims = 64\n",
        "encoder = Encoder(embed_dims)\n",
        "decoder = Decoder(embed_dims)\n",
        "\n",
        "# model save\n",
        "import os\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder = encoder, decoder=decoder)\n",
        "\n",
        "\n",
        "# batch 단위 학습을 위한 training function\n",
        "def train_step(enc_inputs, dec_inputs, dec_outputs, batch_size):\n",
        "\n",
        "    loss = 0\n",
        "    enc_h_init = tf.zeros((batch_size, 256))\n",
        "    enc_c_init = tf.zeros((batch_size, 256))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_state_h, enc_state_c = encoder(enc_inputs, enc_h_init, enc_c_init)\n",
        "        dec_state_h = enc_state_h\n",
        "        dec_state_c = enc_state_c\n",
        "\n",
        "\n",
        "        for t,k in zip(range(0, dec_inputs.shape[1]),range(0, dec_outputs.shape[1])):\n",
        "\n",
        "            dec_input = tf.expand_dims(dec_inputs[:,t],1)\n",
        "            dec_output = tf.expand_dims(dec_outputs[:,k],1)\n",
        "\n",
        "            pred, dec_state_h, dec_state_c = decoder(dec_input, dec_state_h, dec_state_c, enc_output)\n",
        "            loss += loss_func(dec_output, pred)\n",
        "\n",
        "    batch_loss = (loss / int(dec_outputs.shape[1]))\n",
        "\n",
        "    # Backword Propagation and update the weights params\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "EPOCHS = 10\n",
        "batch_size = 512\n",
        "epochs_per_steps = int(len(encoder_input_train) / batch_size)\n",
        "\n",
        "# training\n",
        "import time\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for step in range(epochs_per_steps):\n",
        "\n",
        "        enc_x_batch = encoder_input_train[batch_size * step: batch_size * (step + 1), :]\n",
        "        dec_x_batch = decoder_input_train[batch_size * step: batch_size * (step + 1), :]\n",
        "        dec_y_batch = decoder_output_train[batch_size * step: batch_size * (step + 1), :]\n",
        "\n",
        "        batch_loss = train_step(enc_x_batch, dec_x_batch, dec_y_batch, batch_size)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, step + 1, batch_loss.numpy()))\n",
        "\n",
        "    # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "        \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / epochs_per_steps))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW6T4hqu7nwm"
      },
      "source": [
        "# prediction(translate)\n",
        "\n",
        "def decode_sequence(input_seq, encoder_model, decoder_model):\n",
        "\n",
        "    \n",
        "    enc_h_init = tf.zeros((1, 256))\n",
        "    enc_c_init = tf.zeros((1, 256))\n",
        "    \n",
        "\n",
        "    # encoder\n",
        "    enc_output, enc_state_h, enc_state_c = encoder(input_seq, enc_h_init, enc_c_init)\n",
        "\n",
        "    # decoder\n",
        "    dec_state_h = enc_state_h\n",
        "    dec_state_c = enc_state_c\n",
        "\n",
        "    #<sos>에 대응되는 정수 인덱스 부여\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0,0] = tar_to_index['<sos>']\n",
        "    \n",
        "    stop_cond = False\n",
        "    decode_sentence = ''\n",
        "\n",
        "    while not stop_cond:\n",
        "\n",
        "        output_tokens, dec_state_h, dec_state_c = decoder_model(target_seq, dec_state_h, dec_state_c, enc_output)\n",
        "\n",
        "        # 예측 결과를 단어로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        if sampled_token_index ==0:\n",
        "            break\n",
        "        else:\n",
        "            sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        # 결과를 문장에 추가\n",
        "        decode_sentence += \" \" + sampled_char \n",
        "\n",
        "        # stop condition\n",
        "        if (sampled_char == '<eos>' or len(decode_sentence) >= 50):\n",
        "            stop_cond = True\n",
        "\n",
        "        # 예측된 결과를 다음 hidden_state로 반영\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0,0] = sampled_token_index\n",
        "    \n",
        "    return decode_sentence\n",
        "\n",
        "\n",
        "def seq2src(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            temp = temp + index_to_src[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2tar(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if((i!= 0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
        "            temp = temp + index_to_tar[i] + ' '\n",
        "    return temp\n",
        "\n",
        "for seq_index in [3,10,25,50,100,150,300,500,750,1000,1500, 1750, 2000, 2500]:\n",
        "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq, encoder, decoder)\n",
        "\n",
        "    print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
        "    print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
        "    print(\"예측문 :\",decoded_sentence)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}